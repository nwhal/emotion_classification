{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Class Perceptron for Emotion Classification\n",
    "This notebook contains an implementation of the multi-class perceptron algorithm for emotion classification using the ISEAR dataset. Datafiles are .csv files containing texts tagged with 7 self-reported emotions: joy, fear, anger, sadness, disgust, shame, and guilt. \n",
    "## Perceptron Class\n",
    "The Perceptron class is initialized with 3 parameters: X-train - List of texts for training the model; y-train - List of labels corresponding to X-train; epoch - an integer corresponding to the number of training iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_utils as du\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class definition for perceptron contains methods init, fit, and predict\n",
    "class Perceptron:\n",
    "    def __init__(self, X_train, y_train, epoch):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.epoch = epoch\n",
    "        # These will be updated below\n",
    "        self.features = None\n",
    "        self.weight_vecs = None\n",
    "        self.labels = None\n",
    "\n",
    "        # Create dictionary where features are keys and values are indices\n",
    "        self.features = du.build_vocab(X_train)\n",
    "        \n",
    " \n",
    "        # Get unique labels\n",
    "        self.labels = list(set(y_train))\n",
    "\n",
    "        # Create weight vectors length of vocabulary for each label. This is a 2D dictionary where:\n",
    "        # Keys are labels and values are dictionaries containing a weight (initialized to value between 0-1) for each feature (word) in our vocabulary.\n",
    "        self.weight_vecs = {key: dict() for key in self.labels}\n",
    "        for key in self.weight_vecs:\n",
    "            for i in self.features.keys():\n",
    "                self.weight_vecs[key][i] = random.random()\n",
    "    \n",
    "  \n",
    "    def fit(self):\n",
    "        # We iterate over the model for the specified number of epochs\n",
    "        for i in range(self.epoch):\n",
    "            '''We take the argmax of the dot product of our weights + feature vectors. Since we have 1 for word occurance and 0 for \n",
    "            non-occurance, we will simply take the sum of weights'''\n",
    "            for j in range(len(self.X_train)):\n",
    "                emotion_scores = dict(joy=0, fear=0, guilt=0, anger=0, disgust=0, sadness=0, shame=0)\n",
    "                text = X_train[j].split()\n",
    "                for label in self.labels:\n",
    "                    dot_product = 0\n",
    "                    for word in text:\n",
    "                        dot_product += self.weight_vecs[label][word]\n",
    "                    emotion_scores[label] = dot_product\n",
    "                \n",
    "                predicted_label = max(emotion_scores, key=emotion_scores.get)\n",
    "                true_label = y_train[j]\n",
    "                if predicted_label != true_label:\n",
    "                    for word in text:\n",
    "                        self.weight_vecs[predicted_label][word] -= 1\n",
    "                        self.weight_vecs[true_label][word] += 1\n",
    "    \n",
    "    # Returns list of predicted labels given X_test parameter\n",
    "    def predict(self, X_test):\n",
    "        y_predict = []\n",
    "        for i in range(len(X_test)):\n",
    "            emotion_scores = dict(joy=0, fear=0, guilt=0, anger=0, disgust=0, sadness=0, shame=0)\n",
    "            text = X_test[i].split()\n",
    "            for label in self.labels:\n",
    "                dot_product = 0\n",
    "                for word in text:\n",
    "                    if word in self.features.keys():\n",
    "                        dot_product += self.weight_vecs[label][word]\n",
    "                emotion_scores[label] = dot_product\n",
    "            \n",
    "            predicted_label = max(emotion_scores, key=emotion_scores.get)      \n",
    "            y_predict.append(predicted_label)\n",
    "            \n",
    "        return y_predict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Training and Test Data\n",
    "Now, we first prepare our training and test data to be used by the Perceptron class. This section defines two functions: sep_labels() and prep_data(). The first, sep_labels() decouples the labels from our training documents and returns a list of training documents, X, and a list of corresponding labels, y. The prep_data() function accepts a two arguments: a path to the .csv training data, and a path to the .csv test data. The function returns 4 lists: X_train, y_train, X_test, y_test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate labels\n",
    "def sep_labels(data):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in data:\n",
    "        y.append(i[0])\n",
    "        X.append(i[1])\n",
    "    return X, y\n",
    "\n",
    "# Preparing data for model\n",
    "def prep_data(train_file, test_file):\n",
    "    training_data = du.getdata(train_file)\n",
    "    testing_data = du.getdata(test_file)\n",
    "\n",
    "    X_train, y_train = sep_labels(training_data)\n",
    "    X_test, y_test = sep_labels(testing_data)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = prep_data('isear-train.csv', 'isear-test.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model\n",
    "We initialize the Perceptron with X_traing, y_train, and select a number of epochs. We then call model.fit() to train the model, and model.predict() to receive our list of predicted labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Perceptron(X_train, y_train, epoch = 5)\n",
    "model.fit()\n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "We import the Evaluator class from the evaluator module. The evaluator object is initialized with a list of predictions and true values. From the precision, recall, and f_score values for each label, we can see that the model needs some work. Possible next steps are removing some common stop words and performing TF-IDF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluator import Evaluator\n",
    "\n",
    "eval = Evaluator(predictions, y_test)\n",
    "eval.ret_precision()\n",
    "eval.ret_recall()\n",
    "eval.ret_fscore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joy': 0.5284974093264249, 'fear': 0.6176470588235294, 'guilt': 0.4444444444444444, 'anger': 0.39869281045751637, 'disgust': 0.47904191616766467, 'sadness': 0.47191011235955055, 'shame': 0.4010989010989011}\n",
      "{'joy': 0.6375, 'fear': 0.5121951219512195, 'guilt': 0.32432432432432434, 'anger': 0.3567251461988304, 'disgust': 0.47337278106508873, 'sadness': 0.5637583892617449, 'shame': 0.46794871794871795}\n",
      "{'joy': 0.5779036827195467, 'fear': 0.56, 'guilt': 0.375, 'anger': 0.3765432098765432, 'disgust': 0.4761904761904762, 'sadness': 0.5137614678899083, 'shame': 0.43195266272189353}\n"
     ]
    }
   ],
   "source": [
    "print(eval.precision)\n",
    "print(eval.recall)\n",
    "print(eval.f_score)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
