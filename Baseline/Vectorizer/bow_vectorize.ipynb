{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_utils as du\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a basic implementation of a featurization technique. We first read in the .csv datfile and clean up the text. We then create dictionary of all the word types in our corpus, assigning an integer (an index) for each word. Our sentence vectors are generated by populating a list of indices corresponding to the words in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joy': 762, 'fear': 737, 'anger': 742, 'shame': 731, 'guilt': 737, 'sadness': 741, 'disgust': 736}\n"
     ]
    }
   ],
   "source": [
    "# Get data function returns a 2D list of cleans text where first element of each sublist is label and second element is text\n",
    "x = du.getdata('isear-train.csv')\n",
    "# Count labels gives us a dictionary with the count of each label in the training data\n",
    "labels = du.count_labels(x)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our training data in x, we can generate the dictionary of indices with the build_vocab function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'field': 0, 'wiped': 1, 'maps': 2, 'sorrow': 3, 'coins': 4, 'deeper': 5, 'bribed': 6, 'spontaneous': 7, 'friendship': 8, 'cloth': 9, 'chips': 10, 'guanggho': 11, 'your': 12, 'inflammation': 13, 'entire': 14, 'unit': 15, 'custody': 16, 'coast': 17, 'septic': 18, 'thoughtless': 19, 'bloopers': 20, 'clock': 21, 'obstacles': 22, 'signed': 23, 'commit': 24}\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for i in x:\n",
    "    words.append(i[1])\n",
    "vocab_idcs = du.build_vocab(words)\n",
    "print(dict(itertools.islice(vocab_idcs.items(), 25)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step will be to generate a sentence vector from the indices we have made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7441, 272, 1242, 7678, 2205]\n"
     ]
    }
   ],
   "source": [
    "s = 'i am going to cry'\n",
    "s = s.split()\n",
    "\n",
    "s_vec = []\n",
    "for i in s:\n",
    "    try:\n",
    "        s_vec.append(vocab_idcs[i])\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "print(s_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'i' is at idx: 7441\n",
      "'am' is at idx: 272\n",
      "'going' is at idx: 1242\n",
      "'to' is at idx: 7678\n",
      "'cry' is at idx: 2205\n"
     ]
    }
   ],
   "source": [
    "print(\"'i' is at idx: \" + str(vocab_idcs['i']))\n",
    "print(\"'am' is at idx: \" + str(vocab_idcs['am']))\n",
    "print(\"'going' is at idx: \" + str(vocab_idcs['going']))\n",
    "print(\"'to' is at idx: \" + str(vocab_idcs['to']))\n",
    "print(\"'cry' is at idx: \" + str(vocab_idcs['cry']))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
