{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Class Perceptron for Emotion Classification \n",
    "## *(With TF-IDF Vectors)*\n",
    "This notebook contains an implementation of the multi-class perceptron algorithm for emotion classification using the ISEAR dataset. Datafiles are .csv files containing texts tagged with 7 self-reported emotions: joy, fear, anger, sadness, disgust, shame, and guilt. After data cleaning, the training set contains 5186 texts and the test set contains 1117. \n",
    "## Perceptron Class\n",
    "The Perceptron class is initialized with 3 parameters: X-train - List of texts for training the model; y-train - List of labels corresponding to X-train; epoch - an integer corresponding to the number of training iterations. The weight vectors are a two-dimension dictionary containing 7 weight vectors (one for each label) of vocabulary length. The initial weights are randomized to a value between 0 and 1. \n",
    "\n",
    "The perceptron builds feature vectors using TF-IDF. For each document in our training set, we calculate the term frequency as:\n",
    "\n",
    "$\\frac{word\\ occurrances}{total\\ words}$\n",
    "\n",
    "The inverse document frequency is calculated as:\n",
    "\n",
    "$\\log{_e}{\\frac{num\\ docs}{docs\\ containing\\ word}}$\n",
    "\n",
    "The product of these two values is used to represent each word/feature in the sentences.\n",
    "\n",
    "With each training epoch, for each text, for each emotion label, we take the dot product of the feature vector and corresponding weight vector. The argmax of these calculations is assumed to be the predicted label. If the perceptron has accurately classified the text, we do nothing. If the classification is incorrect, we reward the correct label by adding the feature vector to its weight vector. We penalize the incorrectly predicted label by subtracting the feature vector from its weight vector.\n",
    "\n",
    "Similarly, the predict method vectorizes a list of test data to be classified and returns a list of predictions that are the argmax of the dot product of each feature vector and each weight vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_utils as du\n",
    "import random\n",
    "import tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class definition for perceptron contains methods init, train, and predict\n",
    "class Perceptron:\n",
    "    def __init__(self, X_train, y_train, epoch):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.epoch = epoch\n",
    "        # These will be updated below\n",
    "        self.weight_vecs = None\n",
    "        self.labels = None\n",
    "\n",
    "        #TF_IDF\n",
    "        tf_idf_model = tfidf.Tfidf(self.X_train, Y=self.y_train, train=True)\n",
    "        tf_idf_model.tf_idf()\n",
    "        self.feature_vecs = tf_idf_model.tf_idf_d\n",
    "        # Get unique labels\n",
    "        self.labels = list(set(y_train))\n",
    "\n",
    "        # Create weight vectors length of vocabulary for each label. This is a 2D dictionary where:\n",
    "        # Keys are labels and values are dictionaries containing a weight (initialized to value between 0-1) for each feature (word) in our vocabulary.\n",
    "        self.weight_vecs = {key: dict() for key in self.labels}\n",
    "        for key in self.weight_vecs:\n",
    "            for i in tf_idf_model.unique_tokens:\n",
    "                self.weight_vecs[key][i] = random.random()\n",
    "  \n",
    "    def train(self):\n",
    "        # We iterate over the model for the specified number of epochs\n",
    "        for i in range(self.epoch):\n",
    "            for sent in self.feature_vecs:\n",
    "                # Initialize a dictionary to hold each dot product calculation\n",
    "                emotion_scores = dict(joy=0, fear=0, guilt=0, anger=0, disgust=0, sadness=0, shame=0)\n",
    "                # Calculate the dot product\n",
    "                for label in self.labels:\n",
    "                    dot_product = 0\n",
    "                    for feature in self.feature_vecs[sent]:\n",
    "                        if feature != 'LABEL':\n",
    "                            dot_product += self.feature_vecs[sent][feature] * self.weight_vecs[label][feature]\n",
    "                    \n",
    "                    emotion_scores[label] = dot_product\n",
    "\n",
    "                # Find the argmax\n",
    "                argmax = max(emotion_scores, key=emotion_scores.get)\n",
    "                correct_label = self.feature_vecs[sent]['LABEL']\n",
    "                \n",
    "                # Reward/Penalty update step\n",
    "                if argmax != correct_label:\n",
    "                    for feature in self.feature_vecs[sent]:\n",
    "                        if feature != 'LABEL':\n",
    "                            self.weight_vecs[correct_label][feature] += self.feature_vecs[sent][feature]\n",
    "                            self.weight_vecs[argmax][feature] -= self.feature_vecs[sent][feature]\n",
    "                         \n",
    "\n",
    "    # Returns list of predicted labels given X_test parameter\n",
    "    def predict(self, X_test):\n",
    "        test_model = tfidf.Tfidf(X_test)\n",
    "        test_model.tf_idf()\n",
    "        train_vecs = test_model.tf_idf_d\n",
    "\n",
    "        predictions = []\n",
    "        for sent in train_vecs:\n",
    "            emotion_scores = dict(joy=0, fear=0, guilt=0, anger=0, disgust=0, sadness=0, shame=0)\n",
    "            for label in self.labels:\n",
    "                dot_product = 0\n",
    "                for feature in train_vecs[sent]:\n",
    "                    if feature in self.weight_vecs[label]:\n",
    "                        dot_product += train_vecs[sent][feature] * self.weight_vecs[label][feature]\n",
    "                emotion_scores[label] = dot_product\n",
    "            argmax = max(emotion_scores, key=emotion_scores.get)\n",
    "            predictions.append(argmax)\n",
    "        \n",
    "        return predictions     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Training and Test Data\n",
    "Now, we first prepare our training and test data to be used by the Perceptron class. This section defines two functions: sep_labels() and prep_data(). The first, sep_labels() decouples the labels from our training documents and returns a list of training documents, X, and a list of corresponding labels, y. The prep_data() function accepts a two arguments: a path to the .csv training data, and a path to the .csv test data. The function returns 4 lists: X_train, y_train, X_test, y_test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = du.prep_data('isear-train.csv', 'isear-test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model\n",
    "We initialize the Perceptron with X_traing, y_train, and select a number of epochs. We then call model.fit() to train the model, and model.predict() to receive our list of predicted labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Perceptron(X_train, y_train, epoch = 3)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "We import the Evaluator class from the evaluator module. The evaluator object is initialized with a list of predictions and true values. Using the ret_fscore() method, we can see the presicion, recall, and f1score for each emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluator import Evaluator\n",
    "\n",
    "eval = Evaluator(predictions, y_test)\n",
    "eval.ret_fscore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joy': 0.6132596685082873, 'fear': 0.6219512195121951, 'guilt': 0.37894736842105264, 'anger': 0.4065040650406504, 'disgust': 0.48255813953488375, 'sadness': 0.5899280575539568, 'shame': 0.4391891891891892}\n",
      "{'joy': 0.69375, 'fear': 0.6219512195121951, 'guilt': 0.4864864864864865, 'anger': 0.29239766081871343, 'disgust': 0.4911242603550296, 'sadness': 0.5503355704697986, 'shame': 0.4166666666666667}\n",
      "{'joy': 0.6510263929618768, 'fear': 0.6219512195121951, 'guilt': 0.42603550295857995, 'anger': 0.3401360544217687, 'disgust': 0.4868035190615836, 'sadness': 0.5694444444444444, 'shame': 0.4276315789473685}\n",
      "----------------------------------------------------\n",
      "\n",
      "joy\n",
      "anger\n",
      "fear\n",
      "sadness\n",
      "guilt\n",
      "disgust\n",
      "shame\n",
      "0.7817750543585689\n"
     ]
    }
   ],
   "source": [
    "print(eval.precision)\n",
    "print(eval.recall)\n",
    "print(eval.f_score)\n",
    "print('----------------------------------------------------')\n",
    "print()\n",
    "print(eval.accuracy())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
